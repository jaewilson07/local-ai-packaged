# Apps Stack (n8n, Flowise, Open WebUI, SearXNG, Langfuse, ClickHouse)
# Network: Uses external network ai-network

# Shared configuration anchors
x-logging-json: &logging-json
  driver: "json-file"
  options:
    max-size: "1m"
    max-file: "1"

x-security-chown: &security-chown
  cap_drop:
    - ALL
  cap_add:
    - CHOWN
    - SETGID
    - SETUID
  security_opt:
    - no-new-privileges:true

x-healthcheck-http: &healthcheck-http
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s

networks:
  default:
    external: true
    name: ai-network

# Shared environment variable groups
x-database-env: &database-env
  DB_TYPE: postgresdb
  DB_POSTGRESDB_HOST: supabase-db
  DB_POSTGRESDB_USER: postgres
  DB_POSTGRESDB_PASSWORD: ${POSTGRES_PASSWORD}
  DB_POSTGRESDB_DATABASE: postgres

x-redis-env: &redis-env
  REDIS_HOST: ${REDIS_HOST:-redis}
  REDIS_PORT: ${REDIS_PORT:-6379}
  REDIS_AUTH: ${REDIS_AUTH:-LOCALONLYREDIS}
  REDIS_TLS_ENABLED: ${REDIS_TLS_ENABLED:-false}

x-n8n: &service-n8n
  image: n8nio/n8n:latest
  environment:
    <<: *database-env
    N8N_DIAGNOSTICS_ENABLED: "false"
    N8N_PERSONALIZATION_ENABLED: "false"
    N8N_ENCRYPTION_KEY: ${N8N_ENCRYPTION_KEY}
    N8N_USER_MANAGEMENT_JWT_SECRET: ${N8N_USER_MANAGEMENT_JWT_SECRET}
    WEBHOOK_URL: ${N8N_HOSTNAME:+https://}${N8N_HOSTNAME:-http://localhost:5678}
    # Ollama Integration
    # n8n connects to Ollama via credentials configured in the UI (Settings > Credentials > Ollama)
    # Default Base URL for Docker: http://ollama:11434 (container name on ai-network)
    # For local Ollama (Mac): http://host.docker.internal:11434
    # Google OIDC/SSO Configuration (optional)
    # Note: n8n OIDC is primarily configured via UI (Settings > SSO), but these env vars
    # can be used if n8n supports them. The UI approach is the official method.
    # Uses existing CLIENT_ID_GOOGLE_LOGIN, CLIENT_SECRET_GOOGLE_LOGIN, and OPENID_PROVIDER_URL from .env
    # For OIDC configuration, use: OPENID_PROVIDER_URL (already set, typically https://accounts.google.com/.well-known/openid-configuration)
  networks:
    - default

services:
  # n8n Workflow Automation
  n8n-import:
    <<: *service-n8n
    container_name: n8n-import
    entrypoint: /bin/sh
    command:
      - "-c"
      - "n8n import:credentials --separate --input=/backup/credentials && n8n import:workflow --separate --input=/backup/workflows"
    volumes:
      - ../03-apps/n8n/config/import:/backup

  n8n:
    <<: *service-n8n
    container_name: n8n
    restart: unless-stopped
    expose:
      - 5678/tcp
    volumes:
      - ../03-apps/n8n/data/home:/home/node/.n8n
      - ../03-apps/n8n/data/backup:/backup
      - ../shared:/data/shared
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:5678/healthz"]
      <<: *healthcheck-http

  # Flowise AI Agent Builder
  flowise:
    image: flowiseai/flowise
    restart: unless-stopped
    container_name: flowise
    expose:
      - 3001/tcp
    environment:
      PORT: "3001"
      FLOWISE_USERNAME: ${FLOWISE_USERNAME}
      FLOWISE_PASSWORD: ${FLOWISE_PASSWORD}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ../03-apps/flowise/data:/root/.flowise
    networks:
      - default
    entrypoint: /bin/sh -c "sleep 3; flowise start"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001/api/v1/ping"]
      <<: *healthcheck-http

  # Open WebUI
  open-webui:
    image: ghcr.io/open-webui/open-webui:0.6.43
    restart: unless-stopped
    container_name: open-webui
    expose:
      - 8080/tcp
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      <<: *database-env
      # Open WebUI API URL for Lambda server integration
      OPENWEBUI_API_URL: ${OPENWEBUI_API_URL:-http://open-webui:8080}
      # Lambda server URL for MCP and RAG integration
      LAMBDA_SERVER_URL: ${LAMBDA_SERVER_URL:-http://lambda-server:8000}
      # Google OAuth Configuration (optional)
      # Uses existing CLIENT_ID_GOOGLE_LOGIN and CLIENT_SECRET_GOOGLE_LOGIN from .env
      ENABLE_OAUTH_SIGNUP: ${ENABLE_OAUTH_SIGNUP:-false}
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID:-${CLIENT_ID_GOOGLE_LOGIN:-}}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET:-${CLIENT_SECRET_GOOGLE_LOGIN:-}}
      # OpenID Provider URL for proper logout functionality
      OPENID_PROVIDER_URL: ${OPENID_PROVIDER_URL:-https://accounts.google.com/.well-known/openid-configuration}
      # Merge accounts by email (allows logging into account matching OAuth email)
      OAUTH_MERGE_ACCOUNTS_BY_EMAIL: ${OAUTH_MERGE_ACCOUNTS_BY_EMAIL:-false}
      # Disable login form when OAuth signup is enabled (prevents login issues)
      ENABLE_LOGIN_FORM: ${ENABLE_LOGIN_FORM:-true}
    volumes:
      - ../03-apps/open-webui/data:/app/backend/data
    networks:
      - default
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      <<: *healthcheck-http

  # SearXNG Search Engine
  searxng:
    container_name: searxng
    image: docker.io/searxng/searxng:latest
    restart: unless-stopped
    expose:
      - 8080/tcp
    volumes:
      - ../03-apps/searxng/config:/etc/searxng:rw
    environment:
      SEARXNG_BASE_URL: https://${SEARXNG_HOSTNAME:-localhost}/
      UWSGI_WORKERS: ${SEARXNG_UWSGI_WORKERS:-4}
      UWSGI_THREADS: ${SEARXNG_UWSGI_THREADS:-4}
    <<: *security-chown
    networks:
      - default
    logging: *logging-json

  # ClickHouse (for Langfuse)
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse
    restart: always
    expose:
      - 8123/tcp
      - 9000/tcp
      - 9009/tcp
    environment:
      CLICKHOUSE_DB: default
      CLICKHOUSE_USER: clickhouse
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
    volumes:
      - ../03-apps/clickhouse/data:/var/lib/clickhouse
      - ../03-apps/clickhouse/logs:/var/log/clickhouse-server
    networks:
      - default
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:8123/ping || exit 1
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 30s

  # Langfuse Worker
  langfuse-worker:
    image: langfuse/langfuse-worker:3
    container_name: langfuse-worker
    restart: always
    depends_on:
      # Note: minio is in data stack, so we can't use depends_on here
      # Services will communicate via ai-network, but startup order is not guaranteed
      clickhouse:
        condition: service_healthy
    expose:
     - 3030/tcp
    environment: &langfuse-worker-env
      DATABASE_URL: postgresql://postgres:${POSTGRES_PASSWORD}@supabase-db:5432/postgres
      SALT: ${LANGFUSE_SALT}
      ENCRYPTION_KEY: ${ENCRYPTION_KEY}
      TELEMETRY_ENABLED: ${TELEMETRY_ENABLED:-true}
      LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES: ${LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES:-true}
      CLICKHOUSE_MIGRATION_URL: ${CLICKHOUSE_MIGRATION_URL:-clickhouse://clickhouse:9000}
      CLICKHOUSE_URL: ${CLICKHOUSE_URL:-http://clickhouse:8123}
      CLICKHOUSE_USER: ${CLICKHOUSE_USER:-clickhouse}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
      CLICKHOUSE_CLUSTER_ENABLED: ${CLICKHOUSE_CLUSTER_ENABLED:-false}
      LANGFUSE_S3_EVENT_UPLOAD_BUCKET: ${LANGFUSE_S3_EVENT_UPLOAD_BUCKET:-langfuse}
      LANGFUSE_S3_EVENT_UPLOAD_REGION: ${LANGFUSE_S3_EVENT_UPLOAD_REGION:-auto}
      LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID: ${LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID:-minio}
      LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT: ${LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT:-http://minio:9000}
      LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE: ${LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE:-true}
      LANGFUSE_S3_EVENT_UPLOAD_PREFIX: ${LANGFUSE_S3_EVENT_UPLOAD_PREFIX:-events/}
      LANGFUSE_S3_MEDIA_UPLOAD_BUCKET: ${LANGFUSE_S3_MEDIA_UPLOAD_BUCKET:-langfuse}
      LANGFUSE_S3_MEDIA_UPLOAD_REGION: ${LANGFUSE_S3_MEDIA_UPLOAD_REGION:-auto}
      LANGFUSE_S3_MEDIA_UPLOAD_ACCESS_KEY_ID: ${LANGFUSE_S3_MEDIA_UPLOAD_ACCESS_KEY_ID:-minio}
      LANGFUSE_S3_MEDIA_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      LANGFUSE_S3_MEDIA_UPLOAD_ENDPOINT: ${LANGFUSE_S3_MEDIA_UPLOAD_ENDPOINT:-http://minio:9000}
      LANGFUSE_S3_MEDIA_UPLOAD_FORCE_PATH_STYLE: ${LANGFUSE_S3_MEDIA_UPLOAD_FORCE_PATH_STYLE:-true}
      LANGFUSE_S3_MEDIA_UPLOAD_PREFIX: ${LANGFUSE_S3_MEDIA_UPLOAD_PREFIX:-media/}
      LANGFUSE_S3_BATCH_EXPORT_ENABLED: ${LANGFUSE_S3_BATCH_EXPORT_ENABLED:-false}
      LANGFUSE_S3_BATCH_EXPORT_BUCKET: ${LANGFUSE_S3_BATCH_EXPORT_BUCKET:-langfuse}
      LANGFUSE_S3_BATCH_EXPORT_PREFIX: ${LANGFUSE_S3_BATCH_EXPORT_PREFIX:-exports/}
      LANGFUSE_S3_BATCH_EXPORT_REGION: ${LANGFUSE_S3_BATCH_EXPORT_REGION:-auto}
      LANGFUSE_S3_BATCH_EXPORT_ENDPOINT: ${LANGFUSE_S3_BATCH_EXPORT_ENDPOINT:-http://minio:9000}
      LANGFUSE_S3_BATCH_EXPORT_EXTERNAL_ENDPOINT: ${LANGFUSE_S3_BATCH_EXPORT_EXTERNAL_ENDPOINT:-http://minio:9000}
      LANGFUSE_S3_BATCH_EXPORT_ACCESS_KEY_ID: ${LANGFUSE_S3_BATCH_EXPORT_ACCESS_KEY_ID:-minio}
      LANGFUSE_S3_BATCH_EXPORT_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      LANGFUSE_S3_BATCH_EXPORT_FORCE_PATH_STYLE: ${LANGFUSE_S3_BATCH_EXPORT_FORCE_PATH_STYLE:-true}
      LANGFUSE_INGESTION_QUEUE_DELAY_MS: ${LANGFUSE_INGESTION_QUEUE_DELAY_MS:-}
      LANGFUSE_INGESTION_CLICKHOUSE_WRITE_INTERVAL_MS: ${LANGFUSE_INGESTION_CLICKHOUSE_WRITE_INTERVAL_MS:-}
      <<: *redis-env
      REDIS_TLS_CA: ${REDIS_TLS_CA:-/certs/ca.crt}
      REDIS_TLS_CERT: ${REDIS_TLS_CERT:-/certs/redis.crt}
      REDIS_TLS_KEY: ${REDIS_TLS_KEY:-/certs/redis.key}
    networks:
      - default

  # Langfuse Web
  langfuse-web:
    image: langfuse/langfuse:3
    container_name: langfuse-web
    restart: always
    depends_on:
      # Note: minio is in data stack, so we can't use depends_on here
      # Services will communicate via ai-network, but startup order is not guaranteed
      clickhouse:
        condition: service_healthy
    expose:
      - 3000/tcp
    environment:
      <<: *langfuse-worker-env
      NEXTAUTH_URL: http://localhost:3002
      NEXTAUTH_SECRET: ${NEXTAUTH_SECRET}
      LANGFUSE_INIT_ORG_ID: ${LANGFUSE_INIT_ORG_ID:-}
      LANGFUSE_INIT_ORG_NAME: ${LANGFUSE_INIT_ORG_NAME:-}
      LANGFUSE_INIT_PROJECT_ID: ${LANGFUSE_INIT_PROJECT_ID:-}
      LANGFUSE_INIT_PROJECT_NAME: ${LANGFUSE_INIT_PROJECT_NAME:-}
      LANGFUSE_INIT_PROJECT_PUBLIC_KEY: ${LANGFUSE_INIT_PROJECT_PUBLIC_KEY:-}
      LANGFUSE_INIT_PROJECT_SECRET_KEY: ${LANGFUSE_INIT_PROJECT_SECRET_KEY:-}
      LANGFUSE_INIT_USER_EMAIL: ${LANGFUSE_INIT_USER_EMAIL:-}
      LANGFUSE_INIT_USER_NAME: ${LANGFUSE_INIT_USER_NAME:-}
      LANGFUSE_INIT_USER_PASSWORD: ${LANGFUSE_INIT_USER_PASSWORD:-}
    networks:
      - default

  # Immich PostgreSQL Database
  immich-postgres:
    image: postgres:14
    container_name: immich-postgres
    restart: unless-stopped
    expose:
      - 5432/tcp
    environment:
      POSTGRES_USER: ${IMMICH_DB_USERNAME:-postgres}
      POSTGRES_PASSWORD: ${IMMICH_DB_PASSWORD}
      POSTGRES_DB: ${IMMICH_DB_DATABASE_NAME:-immich}
      POSTGRES_INITDB_ARGS: "-E UTF8"
    volumes:
      - ../03-apps/immich/data/postgres:/var/lib/postgresql/data
    networks:
      - default
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${IMMICH_DB_USERNAME:-postgres} -d ${IMMICH_DB_DATABASE_NAME:-immich}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    logging: *logging-json

  # Immich Typesense (Search Engine)
  immich-typesense:
    image: typesense/typesense:latest
    container_name: immich-typesense
    restart: unless-stopped
    expose:
      - 8108/tcp
      - 8107/tcp
    environment:
      TYPESENSE_API_KEY: ${IMMICH_TYPESENSE_API_KEY}
      TYPESENSE_DATA_DIR: /data
      TYPESENSE_ENABLE_CORS: "true"
    volumes:
      - ../03-apps/immich/data/typesense:/data
    networks:
      - default
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8108/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *logging-json

  # Immich Machine Learning (Face Detection)
  immich-machine-learning:
    image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}
    container_name: immich-machine-learning
    restart: unless-stopped
    expose:
      - 3003/tcp
    environment:
      IMMICH_MACHINE_LEARNING_PORT: 3003
      IMMICH_MACHINE_LEARNING_HOST: 0.0.0.0
      MODEL_CACHE_FOLDER: /cache
    volumes:
      - ../03-apps/immich/data/model-cache:/cache
    networks:
      - default
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3003"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging: *logging-json

  # Immich Microservices (Background Jobs - CPU)
  immich-microservices-cpu:
    profiles: ["cpu"]
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    container_name: immich-microservices-cpu
    restart: unless-stopped
    command: ["start.sh", "microservices"]
    depends_on:
      immich-postgres:
        condition: service_healthy
      immich-typesense:
        condition: service_healthy
    environment:
      DB_HOSTNAME: immich-postgres
      DB_PORT: 5432
      DB_USERNAME: ${IMMICH_DB_USERNAME:-postgres}
      DB_PASSWORD: ${IMMICH_DB_PASSWORD}
      DB_DATABASE_NAME: ${IMMICH_DB_DATABASE_NAME:-immich}
      REDIS_HOSTNAME: ${REDIS_HOST:-redis}
      REDIS_PORT: ${REDIS_PORT:-6379}
      REDIS_DBINDEX: 0
      IMMICH_MACHINE_LEARNING_URL: http://immich-machine-learning:3003
      TYPESENSE_ENABLED: "true"
      TYPESENSE_HOST: immich-typesense
      TYPESENSE_PORT: 8108
      TYPESENSE_PROTOCOL: http
      TYPESENSE_API_KEY: ${IMMICH_TYPESENSE_API_KEY}
      IMMICH_MEDIA_LOCATION: /usr/src/app/upload
      TZ: ${TZ:-UTC}
    volumes:
      - ../03-apps/immich/data/library:/usr/src/app/upload
    networks:
      - default
    logging: *logging-json

  # Immich Microservices (Background Jobs - GPU)
  immich-microservices-gpu:
    profiles: ["gpu-nvidia"]
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    container_name: immich-microservices-gpu
    restart: unless-stopped
    command: ["start.sh", "microservices"]
    depends_on:
      immich-postgres:
        condition: service_healthy
      immich-typesense:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      DB_HOSTNAME: immich-postgres
      DB_PORT: 5432
      DB_USERNAME: ${IMMICH_DB_USERNAME:-postgres}
      DB_PASSWORD: ${IMMICH_DB_PASSWORD}
      DB_DATABASE_NAME: ${IMMICH_DB_DATABASE_NAME:-immich}
      REDIS_HOSTNAME: ${REDIS_HOST:-redis}
      REDIS_PORT: ${REDIS_PORT:-6379}
      REDIS_DBINDEX: 0
      IMMICH_MACHINE_LEARNING_URL: http://immich-machine-learning:3003
      TYPESENSE_ENABLED: "true"
      TYPESENSE_HOST: immich-typesense
      TYPESENSE_PORT: 8108
      TYPESENSE_PROTOCOL: http
      TYPESENSE_API_KEY: ${IMMICH_TYPESENSE_API_KEY}
      IMMICH_MEDIA_LOCATION: /usr/src/app/upload
      TZ: ${TZ:-UTC}
    volumes:
      - ../03-apps/immich/data/library:/usr/src/app/upload
    networks:
      - default
    logging: *logging-json

  # Immich Server (Main API)
  immich-server:
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    container_name: immich-server
    restart: unless-stopped
    command: ["start.sh", "immich"]
    depends_on:
      immich-postgres:
        condition: service_healthy
      immich-typesense:
        condition: service_healthy
    expose:
      - 2283/tcp
    environment:
      DB_HOSTNAME: immich-postgres
      DB_PORT: 5432
      DB_USERNAME: ${IMMICH_DB_USERNAME:-postgres}
      DB_PASSWORD: ${IMMICH_DB_PASSWORD}
      DB_DATABASE_NAME: ${IMMICH_DB_DATABASE_NAME:-immich}
      REDIS_HOSTNAME: ${REDIS_HOST:-redis}
      REDIS_PORT: ${REDIS_PORT:-6379}
      REDIS_DBINDEX: 0
      IMMICH_MACHINE_LEARNING_URL: http://immich-machine-learning:3003
      TYPESENSE_ENABLED: "true"
      TYPESENSE_HOST: immich-typesense
      TYPESENSE_PORT: 8108
      TYPESENSE_PROTOCOL: http
      TYPESENSE_API_KEY: ${IMMICH_TYPESENSE_API_KEY}
      IMMICH_MEDIA_LOCATION: /usr/src/app/upload
      IMMICH_PORT: 2283
      IMMICH_HOST: 0.0.0.0
      TZ: ${TZ:-UTC}
    volumes:
      - ../03-apps/immich/data/library:/usr/src/app/upload
    networks:
      - default
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:2283/api/server-info/ping"]
      <<: *healthcheck-http
    logging: *logging-json